# A catalog of potential pitfalls in machine learning

This curated collection of programs provides a hands-on exploration of the common pitfalls in machine learning using python. These semi-synthetic datasets are practical implementation of the findings in papers [1] and [2].  Although there are various types of errors that can occur in ML pipelines, we have focused on issues that can be identified and addressed through code-based analysis. A comprehensive knowledge of these issues are essential to build reliable and robust ML systems.


 - PF_01 (No test) : Model trained and tested on the same data. This results in a misleading measure of model generalisability.      
 - PF_02 (Reuse test) : Multiple models are evaluated on the same test data. This can lead to over-confident measures of performance
 - PF_03 (Scale early) : Scaling parameters are determined using the whole dataset. This allows information about test data to leak into training.
 - PF_04 (Select early) : Feature selection is done using the whole dataset before splitting. This allows information about test data to leak into training.
 - PF_05 (Augment early) : Data augmentation is done before splitting data into train and test sets. This results in overlap between train and test sets.
 - PF_06 (Subject overlap)  : A dataset known to contain multiple samples per subject is split randomly.This results in overlap between train and test sets.
 - PF_07 (Time series) : The temporal relationship within time series data is not respected. This can result in meaningless models.
 - PF_08 (HPO no nest) : When doing hyperparameter optimisation, standard CV is used rather than nested CV. This can lead to overfitting. 
 - PF_09 (Ensemble leak) :Overlap between data used to test ensemble and data used to train base models. Can result in misleading metrics.
 - PF_10 (Embed leak) : An embedding model is trained on the entire dataset. This allows information about test data to leak.
 - PF_11 (Foundation leak) : Foundation model applied to well-known benchmark. Likely to be in its original train data, leading to data contamination.
 - PF_12 (Bad features) : Applying model expecting numerical features to categorical features. Invalidates assumptions, likely leading to a poor fit. 
 - PF_13 (Wrong task) : Using regression model/metric to solve a classification task. This does not make sense and can lead to confusion.
 - PF_14 (No HPO) : Comparing models that have not been hyperparameter-tuned. Can result in misleading conclusions.
 - PF_15 (No regularize) : Failing to use standard regularisation techniques for deep learning models. This can lead to overfitting.
 - PF_16 (Using accuracy) : Using accuracy as the only metric on imbalanced data. Models that always predict the majority class can have high accuracy.
 - PF_17 (Ill-suited model) : Complex model applied to data predictable using simple model. Leads to unnecessary complexity and resource usage. 
 - PF_18 (No baseline)  : Failing to compare against simple baselines. This can lead to invalid conclusions about the performance of a model.
 - PF_19 (Impute early)  : Doing mean imputation before splitting the data. This allows information about test data to leak into training.
 - PF_20 (One metric) : Failing to evaluate a model with multiple metrics. Can provide an incomplete/misleading picture of model performance.
 
 
## Datasets
 
 - California Housing : https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_california_housing.html
 - Iris Dataset :https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_iris.html
 - SpamBase.data : https://archive.ics.uci.edu/dataset/94/spambase
 - Wisconsin data : https://www.kaggle.com/datasets/uciml/breast-cancer-wisconsin-data
 - Air Passenger statistics : https://www.kaggle.com/datasets/thedevastator/airlines-traffic-passenger-statistics  
 - Parkinsons Telemonitoring dataset :https://archive.ics.uci.edu/dataset/189/parkinsons+telemonitoring {https://archive.ics.uci.edu/ml/machine-learning-databases/parkinsons/telemonitoring/parkinsons_updrs.data}
 - Pima Indians Diabetes Database -https://www.kaggle.com/datasets/uciml/pima-indians-diabetes-database
 - Fashion-MNIST dataset : https://www.tensorflow.org/datasets/catalog/fashion_mnist  
 - Titanic dataset : https://www.kaggle.com/competitions/titanic/data 
 - Adult dataset : https://archive.ics.uci.edu/dataset/2/adult
 - IMDB dataset : https://huggingface.co/datasets/stanfordnlp/imdb
 
 
## Experimental setup 

  - Research Question 1 (RQ1) : How reliable are LLMs at identifying common machine learning pitfalls in programs written for university-level assignments?

  - Research Question 2 (RQ2) : How useful is the feedback generated by LLMs in response to machine learning code samples that contain common pitfalls? 
 
  ### Large Language Models (LLMs)

    - DeepSeek-Coder-V2 - 15.7B parameters
    - Codellama:34b-instruct -33.7B parameters
    - CodeQwen1.5-7B  parameters
    
 ### Prompts, scripts and experiment results are in the 'Results' folder.
      The password to decrypt is available upon request.

## References 
1. Lones, M.A.: Avoiding common machine learning pitfalls. Patterns 5(10) (2024) https://doi.org/10.1016/j.patter.2024.101046
2. Kapoor, S., Cantrell, E.M., Peng, K., Pham, T.H., Bail, C.A., Gundersen, O.E.,Hofman, J.M., Hullman, J., Lones, M.A., Malik, M.M., Nanayakkara, P., Poldrack, R.A., Raji, I.D., Roberts, M., Salganik, M.J., Serra-Garcia, M., Stewart,B.M., Vandewiele, G., Narayanan, A.: Reforms: Consensus-based recommendations for machine-learning-based science. Science Advances 10(18), 3452 (2024) https://doi.org/10.1126/sciadv.adk3452
